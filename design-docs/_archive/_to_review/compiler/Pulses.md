You asked:

Why does Pulse need to be an explicit event inside the patch if everything already runs per frame?

Short answer:
Because time-based state updates must be driven by patch time, not scheduler iterations.

Here is the precise engineering reason.

⸻

1. Scheduler frames are not stable

The runtime loop executes whenever it can:
•	16.6ms at 60fps
•	8.3ms at 120fps
•	2ms when exporting offline
•	irregular under load
•	skipped when tab is backgrounded
•	duplicated when resampling

If stateful blocks (integrators, delays, envelopes, counters, physics, etc.) advance based on “each frame”, their behavior changes when frame rate changes.

That makes:
•	exports incorrect
•	playback nondeterministic
•	remote clients diverge
•	time stretching impossible
•	debugging impossible

So nothing inside the patch is allowed to advance just because a frame ran.

Everything must advance based on time deltas and events derived from time.

⸻

2. What pulse actually is

pulse is not “one event per frame”.

pulse is:

“the event stream that fires when global time crosses a discrete boundary.”

Those boundaries are:
•	cycle wrap (0 → 1)
•	beat boundaries
•	quantization edges
•	user-defined phase partitions
•	export frame boundaries
•	cue points

It is generated by the time system, not by the render loop.

That means:

Situation	Does pulse fire?
normal playback	when a boundary is crossed
high FPS	same as low FPS
offline render	same number of pulses
scrubbing	pulses fire when crossings occur
seeking	pulses fire correctly or not at all
pausing	no pulses
resuming	no fake pulses

It is a semantic clock edge, not a render tick.

⸻

3. Why this must be in the patch graph

Because stateful blocks need to be triggered by time events, not by “the engine ran again”.

Example blocks that depend on pulse:
•	Integrator with reset
•	Envelope (attack/release)
•	Counter
•	LFO sync
•	Triggered noise
•	Beat-sliced motion
•	Physics stepping
•	Sample & hold
•	Pattern generators

They all need a signal like:

"advance one step now"

not:

"the engine looped"

Those are not the same thing.

⸻

4. Why phaseA/phaseB don’t imply pulseA/pulseB

Phase rails are continuous:
•	they are functions of time
•	they represent “where in a cycle we are”

Pulse is discrete:
•	it fires when phase crosses a boundary

You can have multiple phases, but pulse is derived from the primary time quantization, not per-phase.

If you want per-phase triggers, you derive them:

TriggerOnWrap(phaseA)
TriggerOnWrap(phaseB)

That is a patch decision, not a global rail.

⸻

5. Why pulse is not redundant

If you remove pulse and rely on “frames”, you lose:
•	frame-rate independence
•	offline rendering correctness
•	deterministic replay
•	time-stretching
•	multi-client sync
•	debugging causality

If you remove pulse and rely on phase deltas, you lose:
•	exact wrap detection
•	event alignment
•	envelope triggering
•	quantization
•	beat locking

Pulse exists because events are not values.

They are edges in time.

⸻

6. What pulse is in one line

pulse is:

The canonical stream of time boundary crossings emitted by the TimeRoot.

It is the only thing allowed to cause discrete state changes in the patch.

Everything else is continuous math.

⸻

If you want, next we can go through:
•	how pulse is generated from time
•	how it interacts with phaseA / phaseB
•	how state blocks consume it
•	how this makes offline export exact

But the core answer is:

Pulse exists because state cannot be driven by frames.

How pulse is generated from time

pulse is emitted by the TimeRoot as a function of sim time t (monotonic, never loops). It’s a discrete edge stream derived from one or more quantizers.

Canonical generator:
•	Maintain tPrev (last evaluated sim time) and tNow.
•	For each quantizer Q with step size ΔQ (seconds), compute integer step indices:

kPrev = floor(tPrev / ΔQ)
kNow  = floor(tNow  / ΔQ)

	•	If kNow > kPrev, emit N pulses for each crossed boundary (for deterministic catch-up):

For i in (kPrev+1 .. kNow):
•	boundary time tb = i * ΔQ
•	emit pulse event with payload { time: tb, count: i, dt: tb - lastBoundaryTime }

This solves:
•	variable frame rate
•	large dt spikes
•	offline stepping (dt can be 1/24000s and still works)
•	seeking (you can choose whether to emit catch-up pulses or suppress them; spec should define per action)

Data model (what pulse carries):
•	minimally: count (monotonic integer) and time (boundary time in seconds or ms)
•	optionally: subtick if multiple quantizers are multiplexed (see below)

Single bus, multiple quantizers: either
1.	define pulse as a structured event { kind: 'pulse', lane: 'beat'|'bar'|'frame'|..., count, time }, or
2.	keep pulse as one canonical quantizer and derive other pulses in-patch (recommended unless you truly need multiple global rails for events).

How pulse interacts with phaseA / phaseB

Phases are continuous rails derived from the same sim time, with independent cycle periods:

phaseA = frac(t / periodA)              // in [0,1)
phaseB = frac(t / periodB)

Pulse is not “for phaseA” or “for phaseB”. It’s a global discrete clock. Interaction happens in two ways:

A) Derive per-phase wraps (most common)

You derive phase-specific triggers via edge detection on the phase rails:
•	wrapA = TriggerOnWrap(phaseA)  (fires when phaseA crosses 1→0)
•	wrapB = TriggerOnWrap(phaseB)

This keeps the global system small and predictable.

B) Quantize state updates to pulse boundaries

Many state blocks should step on pulses rather than on arbitrary dt, e.g. “advance my LFO only on beat ticks”.

Pattern:
•	phaseA gives continuous “where we are”
•	pulse gives “when to commit a discrete change”
•	you choose whether a block is continuous-time or event-stepped

C) Keep continuous-time stable across speed changes

If speed changes, t changes slope; phases remain continuous as functions of t, and pulse boundaries remain consistent because they’re computed from t—not from wall-time frames.

How state blocks consume pulse

State blocks should support two update modes:

1) Continuous-time state (dt-driven)

For integrators, filters, physics-like continuous systems:

Inputs:
•	time (or dt) from TimeRoot (or a derived DeltaTime signal)
•	optional reset event

Update each evaluation using exact dt:
•	x = x + f(x, inputs) * dt
•	deterministic as long as dt integration scheme is deterministic

2) Event-stepped state (pulse-driven)

For counters, sequencers, sample-and-hold, envelopes triggered on beats:

Inputs:
•	pulse event stream
•	optional gate, reset, trigger

Mechanics:
•	The executor delivers a list of pulses crossed between tPrev..tNow (including multiple).
•	The block iterates pulses in order and applies transitions deterministically:
•	count++ per pulse
•	envelope stage changes at specific pulse counts
•	sequencer advances exactly N steps even if dt was huge

Critical point: event-stepped blocks must process all missed pulses, not just “pulse happened”.

So the runtime interface for event<trigger> should be something like:
•	EventSpan { n: number; times?: Float64Array; counts?: Uint32Array }
or at minimum
•	n plus firstCount (since boundary times are derivable)

How this makes offline export exact

Offline export means you control the sampling schedule explicitly.

Two export modes become exact:

A) Frame-accurate video export

You step sim time by exactly:
•	dt = 1/fps (e.g. 1/60) for each frame i
•	t = i * dt

Because:
•	phases are pure functions of t
•	pulses are derived from boundary crossings in tPrev..tNow
•	state blocks process either dt or pulse spans

You get identical results regardless of machine speed.

B) Subframe-accurate export (motion blur, temporal supersampling)

You run multiple substeps per output frame:
•	for each frame i:
•	for s in 0..S-1:
•	t = (i + (s+0.5)/S)/fps
•	evaluate
•	accumulate

Pulse generation still works because you may cross boundaries between substeps; if you need “pulse semantics at exact boundaries”, you can:
•	include boundary times in the pulse span, or
•	force the exporter to split steps exactly on boundaries (rarely necessary, but possible)

Determinism guarantee

Given:
•	same patch
•	same initial state seed
•	same sim-time sampling schedule

You get bitwise-stable output (modulo floating point differences if you change JS vs WASM, but the semantics remain identical).
